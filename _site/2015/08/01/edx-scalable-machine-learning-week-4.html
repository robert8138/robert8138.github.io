<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>EdX: Scalable Machine Learning Week 4 Notes</title>
  <meta name="description" content="Lecture Highlights">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://yourdomain.com/2015/08/01/edx-scalable-machine-learning-week-4.html">
  <link rel="alternate" type="application/rss+xml" title="Robert Chang's Personal Website" href="http://yourdomain.com/feed.xml" />
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Robert Chang's Personal Website</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">EdX: Scalable Machine Learning Week 4 Notes</h1>
    <p class="post-meta">Aug 1, 2015</p>
  </header>

  <article class="post-content">
    <h3 id="lecture-highlights"><strong>Lecture Highlights</strong></h3>

<ul>
  <li>
    <p><strong>CTR prediction</strong> is the canonical Machine Learning problem involving Logistic Regression</p>
  </li>
  <li><strong>Players</strong> involve:
    <ul>
      <li><em>Publishers</em>: Make money displaying Ads on their sites (e.g. NYTimes)</li>
      <li><em>Matchmakers</em>: Match publishers with advertisers (e.g. Mopub, Google)</li>
      <li><em>Advertisers</em>: Pay for their ads to be displayed. Want to attract business and drive conversion (e.g. Marc Jacob)</li>
    </ul>
  </li>
  <li>CTR prediction using <strong>logistic regression model</strong>
    <ul>
      <li>Observations are user-ad-publisher triplets</li>
      <li>Labels are {not-click, click}</li>
      <li>Given a set of labeled observations, we want to predict whether a new user-ad-publisher triplet will result in a click</li>
    </ul>
  </li>
  <li><strong>Evaluation Criterion</strong> is typically 0-1 loss: penalty is 0 for correct prediction, and 1 otherwise
    <ul>
      <li>0-1 loss function is not convex, so we approximate it</li>
      <li>SVM (hinge), Logistic Regression (log-loss), Adaboost (exponential)</li>
    </ul>
  </li>
  <li><strong>ROC curve</strong> plots False Positive Rate with True Positive Rate
    <ul>
      <li>A random classifier will fall on 45 degree line, depending on the threshold. Not hard to think about, since the denominator for FP is negative examples, and TP is positive examples. A random classifier with threshold t would just predict + with t% of the time. This is true for both FP and TP, so the performance would fall on 45 degree line.</li>
    </ul>
  </li>
  <li>Again, remember the <strong>intuition of log-loss</strong></li>
</ul>

<h4 id="categorical-data-and-feature-encoding"><strong>Categorical Data and Feature Encoding</strong>:</h4>
<p>Raw data is often non-numeric, how do we handle them?</p>

<ul>
  <li>Use Method that support categorical feature (Decision tree, Naive Bayes), but model options are limited</li>
  <li>Convert these categorical features to numeric feature
    <ul>
      <li>Encode category to numeric. e.g. cat1 = 1, cat2 = 2, catx = x …etc. Not good!! since this introduces inherent ordering, which might not be there. (ordinal - not ideal, categorial - bad)</li>
      <li>Better approaches include (One-Hot-Encoding) &amp; (Feature Hashing)</li>
    </ul>
  </li>
</ul>

<h4 id="one-hot-encoding"><strong>One-Hot-Encoding</strong></h4>

<ul>
  <li>Step 1: Create OHE Dictionary. See <a href="https://courses.edx.org/c4x/BerkeleyX/CS190.1x/asset/CS190.1x_week4b.pdf">Slide</a></li>
  <li>Step 2: Create Features with Dictionary (bag of word dictionary from training set)</li>
  <li>Step 3: Create Sparse OHE feature</li>
</ul>

<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">Animal</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;bear&#39;</span><span class="p">,</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span><span class="s1">&#39;mouse&#39;</span><span class="p">};</span> <span class="no">Color</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">tabby</span><span class="s1">&#39;} </span>
<span class="s1">=&gt; </span>
<span class="s1">(Animal, &#39;</span><span class="n">bear</span><span class="s1">&#39;) =&gt; 0, (Animal, &#39;</span><span class="n">cat</span><span class="s1">&#39;) =&gt; 1, (Animal, &#39;</span><span class="n">mouse</span><span class="s1">&#39;) =&gt; 2, (Color, &#39;</span><span class="n">black</span><span class="s1">&#39;) =&gt; 3, ...etc</span>

<span class="s1">A1 = [&#39;</span><span class="n">mouse</span><span class="s1">&#39;, &#39;</span><span class="n">black</span><span class="err">&#39;</span><span class="p">,</span> <span class="o">-]</span> <span class="o">=&gt;</span> <span class="no">A1</span> <span class="o">=</span> <span class="o">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="o">]</span>

<span class="no">A1</span> <span class="o">=</span> <span class="o">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="o">]</span> <span class="o">-&gt;</span> <span class="no">A1</span> <span class="o">=</span> <span class="o">[</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">]</span></code></pre></div>

<p>OHE suffers from some issues. <strong>Statistically</strong>: inefficient learning. <strong>Computationally</strong>: increased communication in parallel algorithm. Can reduce dimension by discarding rare features, but might throw away useful information.</p>

<h4 id="feature-hashing"><strong>Feature Hashing</strong></h4>

<ul>
  <li>Use hashing principle to reduce feature dimension</li>
  <li>Obviates need to compute expensive OHE dictionary</li>
  <li>Preserves sparsity</li>
  <li>Theoretical underpinning - approximate OHE dot-product-ing</li>
</ul>

<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="ss">Daatapoints</span><span class="p">:</span> <span class="mi">7</span> <span class="n">feature</span> <span class="n">categories</span>
<span class="no">Hash</span> <span class="ss">buckets</span><span class="p">:</span> <span class="n">m</span> <span class="o">=</span> <span class="mi">4</span>
<span class="no">A1</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;mouse&#39;</span><span class="p">,</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="o">-]</span>
<span class="n">H</span><span class="p">(</span><span class="no">Animal</span><span class="p">,</span> <span class="s1">&#39;mouse&#39;</span><span class="p">)</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">H</span><span class="p">(</span><span class="no">Color</span><span class="p">,</span> <span class="s1">&#39;black&#39;</span><span class="p">)</span> <span class="o">=</span> <span class="mi">2</span>
<span class="no">A1</span> <span class="o">=</span> <span class="o">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">1</span><span class="o">]</span>

<span class="no">A2</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;tabby&#39;</span><span class="p">,</span> <span class="s1">&#39;mouse&#39;</span><span class="o">]</span>
<span class="n">H</span><span class="p">(</span><span class="no">Animal</span><span class="p">,</span> <span class="err">’</span><span class="n">cat</span><span class="err">’</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">H</span><span class="p">(</span><span class="no">Color</span><span class="p">,</span> <span class="err">’</span><span class="n">tabby</span><span class="err">’</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">H</span><span class="p">(</span><span class="no">Diet</span><span class="p">,</span> <span class="err">’</span><span class="n">mouse</span><span class="err">’</span><span class="p">)</span> <span class="o">=</span> <span class="mi">2</span>
<span class="no">A2</span> <span class="o">=</span> <span class="o">[</span><span class="mi">2</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">0</span><span class="o">]</span></code></pre></div>

<hr />

<h3 id="labs-highlights"><strong>Labs Highlights</strong></h3>

<ul>
  <li>A good practice in coding is if you need to do some complex operation/transformation, it’s always good to try it out on a few sample examples. Write tests to verify that you understand how it works before moving on and apply it to the whole dataset. Once you understand how it works, you can define the transformation function.</li>
</ul>

<h4 id="one-hot-encoding-1"><strong>One Hot Encoding</strong></h4>

<ul>
  <li>Step 1: Extract features</li>
  <li>Step 2: Create a Dictionary</li>
  <li>Step 3: Create the OHE function</li>
  <li>Step 4: Use OHE to create proper training data</li>
</ul>

<p><strong>Extract features</strong></p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">parsePoint</span><span class="p">(</span><span class="n">point</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts a comma separated string into a list of (featureID, value) tuples.</span>

<span class="sd">    Note:</span>
<span class="sd">        featureIDs should start at 0 and increase to the number of features - 1.</span>

<span class="sd">    Args:</span>
<span class="sd">        point (str): A comma separated string where the first value is the label and the rest</span>
<span class="sd">            are features.</span>

<span class="sd">    Returns:</span>
<span class="sd">        list: A list of (featureID, value) tuples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">point</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;,&#39;</span><span class="p">)</span>
    <span class="n">label</span><span class="p">,</span> <span class="n">rawFeats</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="k">return</span> <span class="p">[(</span><span class="n">featureId</span><span class="p">,</span> <span class="n">featureVal</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">featureId</span><span class="p">,</span> <span class="n">featureVal</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">rawFeats</span><span class="p">)]</span></code></pre></div>

<p><strong>Automated creation of an OHE dictionary</strong></p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">createOneHotDict</span><span class="p">(</span><span class="n">inputData</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a one-hot-encoder dictionary based on the input data.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputData (RDD of lists of (int, str)): An RDD of observations where each observation is</span>
<span class="sd">            made up of a list of (featureID, value) tuples.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: A dictionary where the keys are (featureID, value) tuples and map to values that are</span>
<span class="sd">            unique integers.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">DistinctFeats</span> <span class="o">=</span> <span class="p">(</span><span class="n">inputData</span>
                     <span class="o">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">)</span>
                     <span class="o">.</span><span class="n">distinct</span><span class="p">())</span>
    <span class="n">OHEDict</span> <span class="o">=</span> <span class="p">(</span><span class="n">DistinctFeats</span>
               <span class="o">.</span><span class="n">zipWithIndex</span><span class="p">()</span>
               <span class="o">.</span><span class="n">collectAsMap</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">OHEDict</span></code></pre></div>

<p><strong>Create oneHotEncoding function</strong></p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">oneHotEncoding</span><span class="p">(</span><span class="n">rawFeats</span><span class="p">,</span> <span class="n">OHEDict</span><span class="p">,</span> <span class="n">numOHEFeats</span><span class="p">):</span>
<span class="sd">&quot;&quot;&quot;Produce a one-hot-encoding from a list of features and an OHE dictionary.</span>

<span class="sd">    Note:</span>
<span class="sd">        You should ensure that the indices used to create a SparseVector are sorted.</span>

<span class="sd">    Args:</span>
<span class="sd">        rawFeats (list of (int, str)): The features corresponding to a single observation.  Each</span>
<span class="sd">            feature consists of a tuple of featureID and the feature&#39;s value. (e.g. sampleOne)</span>
<span class="sd">        OHEDict (dict): A mapping of (featureID, value) to unique integer.</span>
<span class="sd">        numOHEFeats (int): The total number of unique OHE features (combinations of featureID and</span>
<span class="sd">            value).</span>

<span class="sd">    Returns:</span>
<span class="sd">        SparseVector: A SparseVector of length numOHEFeats with indicies equal to the unique</span>
<span class="sd">            identifiers for the (featureID, value) combinations that occur in the observation and</span>
<span class="sd">            with values equal to 1.0.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">args</span> <span class="o">=</span> <span class="p">[(</span><span class="n">OHEDict</span><span class="p">[(</span><span class="n">featureID</span><span class="p">,</span> <span class="n">featureValue</span><span class="p">)],</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">featureID</span><span class="p">,</span> <span class="n">featureValue</span><span class="p">)</span> <span class="ow">in</span> <span class="n">rawFeats</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">SparseVector</span><span class="p">(</span><span class="n">numOHEFeats</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span></code></pre></div>

<p><strong>Generate Training Set using LabeledPoint</strong></p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">parseOHEPoint</span><span class="p">(</span><span class="n">point</span><span class="p">,</span> <span class="n">OHEDict</span><span class="p">,</span> <span class="n">numOHEFeats</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Obtain the label and feature vector for this raw observation.</span>

<span class="sd">    Note:</span>
<span class="sd">        You must use the function `oneHotEncoding` in this implementation or later portions</span>
<span class="sd">        of this lab may not function as expected.</span>

<span class="sd">    Args:</span>
<span class="sd">        point (str): A comma separated string where the first value is the label and the rest</span>
<span class="sd">            are features.</span>
<span class="sd">        OHEDict (dict of (int, str) to int): Mapping of (featureID, value) to unique integer.</span>
<span class="sd">        numOHEFeats (int): The number of unique features in the training dataset.</span>

<span class="sd">    Returns:</span>
<span class="sd">        LabeledPoint: Contains the label for the observation and the one-hot-encoding of the</span>
<span class="sd">            raw features based on the provided OHE dictionary.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">point</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;,&#39;</span><span class="p">)</span>
    <span class="n">label</span><span class="p">,</span> <span class="n">rawFeats</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">rawFeatures</span> <span class="o">=</span> <span class="p">[(</span><span class="n">featureID</span><span class="p">,</span> <span class="n">featureVal</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">featureID</span><span class="p">,</span> <span class="n">featureVal</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">rawFeats</span><span class="p">)]</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">oneHotEncoding</span><span class="p">(</span><span class="n">rawFeatures</span><span class="p">,</span> <span class="n">OHEDict</span><span class="p">,</span> <span class="n">numOHEFeats</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">LabeledPoint</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">features</span><span class="p">)</span></code></pre></div>

<h4 id="logistic-regression-modeling"><strong>Logistic Regression Modeling</strong></h4>

<ul>
  <li>Step 1: Define Compute Log Loss function</li>
  <li>Step 2: Compute Baseline Logloss</li>
  <li>Step 3: Compute Model logloss</li>
</ul>

<p><strong>Compute Log Loss</strong></p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">computeLogLoss</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates the value of log loss for a given probabilty and label.</span>

<span class="sd">    Note:</span>
<span class="sd">        log(0) is undefined, so when p is 0 we need to add a small value (epsilon) to it</span>
<span class="sd">        and when p is 1 we need to subtract a small value (epsilon) from it.</span>

<span class="sd">    Args:</span>
<span class="sd">        p (float): A probabilty between 0 and 1.</span>
<span class="sd">        y (int): A label.  Takes on the values 0 and 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: The log loss value.</span>
<span class="sd">    &quot;&quot;&quot;</span>    
    <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">10e-12</span>
    <span class="k">if</span> <span class="n">p</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">p</span> <span class="o">+</span> <span class="n">epsilon</span>
    <span class="k">elif</span> <span class="n">p</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">p</span> <span class="o">-</span> <span class="n">epsilon</span>
    <span class="k">return</span> <span class="n">y</span> <span class="o">*</span> <span class="o">-</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">))</span></code></pre></div>

<p><strong>Baseline Log Loss</strong></p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">classOneFracTrain</span> <span class="o">=</span> <span class="n">OHETrainData</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">lp</span><span class="p">:</span> <span class="n">lp</span><span class="o">.</span><span class="n">label</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">OHETrainData</span><span class="o">.</span><span class="n">collect</span><span class="p">())</span>
<span class="k">print</span> <span class="n">classOneFracTrain</span>

<span class="n">logLossTrBase</span> <span class="o">=</span> <span class="n">OHETrainData</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">lp</span><span class="p">:</span> <span class="n">computeLogLoss</span><span class="p">(</span><span class="n">classOneFracTrain</span><span class="p">,</span> <span class="n">lp</span><span class="o">.</span><span class="n">label</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">OHETrainData</span><span class="o">.</span><span class="n">collect</span><span class="p">())</span></code></pre></div>

<p><strong>Compute Model Logloss</strong></p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model0</span> <span class="o">=</span> <span class="n">LogisticRegressionWithSGD</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">OHETrainData</span><span class="p">,</span> 
                                         <span class="n">iterations</span> <span class="o">=</span> <span class="n">numIters</span><span class="p">,</span> 
                                         <span class="n">step</span> <span class="o">=</span> <span class="n">stepSize</span><span class="p">,</span> 
                                         <span class="n">miniBatchFraction</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> 
                                         <span class="n">initialWeights</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> 
                                         <span class="n">regParam</span> <span class="o">=</span> <span class="n">regParam</span><span class="p">,</span> 
                                         <span class="n">regType</span> <span class="o">=</span> <span class="n">regType</span><span class="p">,</span> 
                                         <span class="n">intercept</span> <span class="o">=</span> <span class="n">includeIntercept</span><span class="p">)</span></code></pre></div>

<p><strong>Define prediction function</strong></p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">getP</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">intercept</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculate the probability for an observation given a set of weights and intercept.</span>

<span class="sd">    Note:</span>
<span class="sd">        We&#39;ll bound our raw prediction between 20 and -20 for numerical purposes.</span>

<span class="sd">    Args:</span>
<span class="sd">        x (SparseVector): A vector with values of 1.0 for features that exist in this</span>
<span class="sd">            observation and 0.0 otherwise.</span>
<span class="sd">        w (DenseVector): A vector of weights (betas) for the model.</span>
<span class="sd">        intercept (float): The model&#39;s intercept.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: A probability between 0 and 1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rawPrediction</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="n">intercept</span>

    <span class="c"># Bound the raw prediction value</span>
    <span class="n">rawPrediction</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">rawPrediction</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
    <span class="n">rawPrediction</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">rawPrediction</span><span class="p">,</span> <span class="o">-</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">sigmoid</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">rawPrediction</span><span class="p">))</span> <span class="o">**</span> <span class="o">-</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">sigmoid</span>
    
<span class="n">trainingPredictions</span> <span class="o">=</span> <span class="n">OHETrainData</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">lp</span><span class="p">:</span> <span class="n">getP</span><span class="p">(</span><span class="n">lp</span><span class="o">.</span><span class="n">features</span><span class="p">,</span> <span class="n">model0</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">model0</span><span class="o">.</span><span class="n">intercept</span><span class="p">))</span></code></pre></div>

<p><strong>Evaluate the model</strong></p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">evaluateResults</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates the log loss for the data given the model.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (LogisticRegressionModel): A trained logistic regression model.</span>
<span class="sd">        data (RDD of LabeledPoint): Labels and features for each observation.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: Log loss for the data.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">resultVector</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">lp</span><span class="p">:</span> <span class="n">computeLogLoss</span><span class="p">(</span><span class="n">getP</span><span class="p">(</span><span class="n">lp</span><span class="o">.</span><span class="n">features</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept</span><span class="p">),</span> <span class="n">lp</span><span class="o">.</span><span class="n">label</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">resultVector</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">resultVector</span><span class="o">.</span><span class="n">collect</span><span class="p">())</span>
    
<span class="n">logLossTrLR0</span> <span class="o">=</span> <span class="n">evaluateResults</span><span class="p">(</span><span class="n">model0</span><span class="p">,</span> <span class="n">OHETrainData</span><span class="p">)</span></code></pre></div>

<h4 id="feature-hashing-1"><strong>Feature Hashing</strong></h4>

<ul>
  <li>Step 1: Create Hash function</li>
  <li>Step 2: Create Hashed feature</li>
  <li>Step 3: Train Model based on hashed features</li>
</ul>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">hashFunction</span><span class="p">(</span><span class="n">numBuckets</span><span class="p">,</span> <span class="n">rawFeats</span><span class="p">,</span> <span class="n">printMapping</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculate a feature dictionary for an observation&#39;s features based on hashing.</span>

<span class="sd">    Note:</span>
<span class="sd">        Use printMapping=True for debug purposes and to better understand how the hashing works.</span>

<span class="sd">    Args:</span>
<span class="sd">        numBuckets (int): Number of buckets to use as features.</span>
<span class="sd">        rawFeats (list of (int, str)): A list of features for an observation.  Represented as</span>
<span class="sd">            (featureID, value) tuples.</span>
<span class="sd">        printMapping (bool, optional): If true, the mappings of featureString to index will be</span>
<span class="sd">            printed.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict of int to float:  The keys will be integers which represent the buckets that the</span>
<span class="sd">            features have been hashed to.  The value for a given key will contain the count of the</span>
<span class="sd">            (featureID, value) tuples that have hashed to that key.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mapping</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">category</span> <span class="ow">in</span> <span class="n">rawFeats</span><span class="p">:</span>
        <span class="n">featureString</span> <span class="o">=</span> <span class="n">category</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>
        <span class="n">mapping</span><span class="p">[</span><span class="n">featureString</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">(</span><span class="n">featureString</span><span class="p">)</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">(),</span> <span class="mi">16</span><span class="p">)</span> <span class="o">%</span> <span class="n">numBuckets</span><span class="p">)</span>
    <span class="k">if</span><span class="p">(</span><span class="n">printMapping</span><span class="p">):</span> <span class="k">print</span> <span class="n">mapping</span>
    <span class="n">sparseFeatures</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">bucket</span> <span class="ow">in</span> <span class="n">mapping</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="n">sparseFeatures</span><span class="p">[</span><span class="n">bucket</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">sparseFeatures</span><span class="p">)</span></code></pre></div>

<p><strong>Create Hashed feature</strong></p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">parseHashPoint</span><span class="p">(</span><span class="n">point</span><span class="p">,</span> <span class="n">numBuckets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a LabeledPoint for this observation using hashing.</span>

<span class="sd">    Args:</span>
<span class="sd">        point (str): A comma separated string where the first value is the label and the rest are</span>
<span class="sd">            features.</span>
<span class="sd">        numBuckets: The number of buckets to hash to.</span>

<span class="sd">    Returns:</span>
<span class="sd">        LabeledPoint: A LabeledPoint with a label (0.0 or 1.0) and a SparseVector of hashed</span>
<span class="sd">            features.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">point</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;,&#39;</span><span class="p">)</span>
    <span class="n">label</span><span class="p">,</span> <span class="n">rawFeats</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="c">#zipWIthIndex</span>
    <span class="n">rawFeaturePairs</span> <span class="o">=</span> <span class="p">[(</span><span class="n">featureID</span><span class="p">,</span> <span class="n">featureVal</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">featureID</span><span class="p">,</span> <span class="n">featureVal</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">rawFeats</span><span class="p">))]</span>
    <span class="n">hashedFeature</span> <span class="o">=</span> <span class="n">hashFunction</span><span class="p">(</span><span class="n">numBuckets</span><span class="p">,</span> <span class="n">rawFeaturePairs</span><span class="p">)</span>
    <span class="n">SparsedHashedFeature</span> <span class="o">=</span> <span class="n">SparseVector</span><span class="p">(</span><span class="n">numBuckets</span><span class="p">,</span> <span class="n">hashedFeature</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">LabeledPoint</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">SparsedHashedFeature</span><span class="p">)</span></code></pre></div>

<p><strong>Train a logistic regression model based on hashed features</strong></p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">stepSizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">regParams</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">]</span>
<span class="k">for</span> <span class="n">stepSize</span> <span class="ow">in</span> <span class="n">stepSizes</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">regParam</span> <span class="ow">in</span> <span class="n">regParams</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="p">(</span><span class="n">LogisticRegressionWithSGD</span>
                 <span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">hashTrainData</span><span class="p">,</span> <span class="n">numIters</span><span class="p">,</span> <span class="n">stepSize</span><span class="p">,</span> <span class="n">regParam</span><span class="o">=</span><span class="n">regParam</span><span class="p">,</span> <span class="n">regType</span><span class="o">=</span><span class="n">regType</span><span class="p">,</span>
                        <span class="n">intercept</span><span class="o">=</span><span class="n">includeIntercept</span><span class="p">))</span>
        <span class="n">logLossVa</span> <span class="o">=</span> <span class="n">evaluateResults</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">hashValidationData</span><span class="p">)</span>
        <span class="k">print</span> <span class="p">(</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">stepSize = {0:.1f}, regParam = {1:.0e}: logloss = {2:.3f}&#39;</span>
               <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">stepSize</span><span class="p">,</span> <span class="n">regParam</span><span class="p">,</span> <span class="n">logLossVa</span><span class="p">))</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">logLossVa</span> <span class="o">&lt;</span> <span class="n">bestLogLoss</span><span class="p">):</span>
            <span class="n">bestModel</span> <span class="o">=</span> <span class="n">model</span>
            <span class="n">bestLogLoss</span> <span class="o">=</span> <span class="n">logLossVa</span></code></pre></div>

  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li>All Rights Reserved | 2015</li>
          <li><a href="mailto:robert8138@gmail.com">robert8138@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/robert8138">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">robert8138</span>
            </a>
          </li>
          

          
          <li>
            <a href="https://twitter.com/_rchang">
              <span class="icon  icon--twitter">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                  c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
                </svg>
              </span>

              <span class="username">_rchang</span>
            </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <ul class="social-media-list">
          
          <li>
            <a href="https://quora.com/Robert-Chang-1">
              <span class="icon  icon--twitter">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg"
                   width="100.000000pt" height="100.000000pt" viewBox="0 0 100.000000 100.000000"
                    preserveAspectRatio="xMidYMid meet">
                    <g transform="translate(0.000000,100.000000) scale(0.100000,-0.100000)"
                    fill="#000000" stroke="none">
                    <path d="M430 924 c-209 -45 -354 -270 -319 -494 23 -148 114 -275 239 -334
                    59 -28 74 -31 165 -31 91 0 105 3 160 30 285 144 325 556 73 756 -90 71 -206
                    98 -318 73z m160 -165 c95 -43 140 -117 140 -231 0 -63 -4 -80 -30 -125 -17
                    -29 -35 -53 -40 -53 -22 0 -9 -41 16 -52 23 -11 29 -10 44 10 34 42 58 21 36
                    -31 -31 -75 -112 -91 -169 -33 -30 30 -41 34 -99 38 -85 5 -150 43 -193 112
                    -37 60 -47 168 -22 229 56 132 195 192 317 136z"/>
                    <path d="M443 715 c-53 -23 -68 -64 -68 -185 0 -118 14 -159 65 -185 28 -15
                    90 -21 90 -9 0 22 -40 66 -72 79 -45 17 -47 27 -13 43 49 22 95 13 142 -30
                    l21 -20 8 47 c10 68 0 175 -20 213 -17 33 -66 62 -103 62 -10 -1 -32 -7 -50
                    -15z"/>
                    </g>
                    </svg>
              </span>

              <span class="username">Robert-Chang-1</span>
            </a>
          </li>
          

          
          <li>
            <a href="https://medium.com/@rchang">
              <span class="icon  icon--twitter">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg"
                   width="100.000000pt" height="100.000000pt" viewBox="0 0 100.000000 100.000000"
                    preserveAspectRatio="xMidYMid meet">
                    <g transform="translate(0.000000,100.000000) scale(0.100000,-0.100000)"
                    fill="#000000" stroke="none">
                    <path d="M200 705 c0 -24 5 -35 14 -35 8 0 18 -4 21 -10 8 -13 8 -307 0 -320
                    -3 -6 -13 -10 -21 -10 -9 0 -14 -11 -14 -35 l0 -35 90 0 90 0 0 34 c0 27 -4
                    35 -20 38 -19 3 -20 11 -23 145 -1 78 1 139 4 135 4 -4 26 -77 49 -162 22 -85
                    43 -163 46 -173 5 -14 14 -17 47 -15 l41 3 48 175 c26 96 50 180 52 185 3 6 5
                    -58 5 -142 1 -150 1 -152 -21 -155 -18 -2 -23 -10 -23 -33 l0 -30 108 -3 107
                    -3 0 36 c0 24 -5 35 -14 35 -8 0 -18 4 -21 10 -3 5 -6 77 -6 160 0 83 3 155 6
                    160 3 6 13 10 21 10 9 0 14 11 14 35 l0 36 -112 -3 -113 -3 -35 -127 c-19 -71
                    -37 -128 -40 -128 -3 0 -21 57 -40 128 l-35 127 -112 3 -113 3 0 -36z"/>
                    </g>
                    </svg>
              </span>

              <span class="username">rchang</span>
            </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col  footer-col-4">
        <ul class="social-media-list">
          
          <li>
            <a href="https://www.linkedin.com/pub/robert-chang/20/b17/877">
              <span class="icon  icon--twitter">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg"
                   width="100.000000pt" height="100.000000pt" viewBox="0 0 100.000000 100.000000"
                    preserveAspectRatio="xMidYMid meet">
                    <g transform="translate(0.000000,100.000000) scale(0.100000,-0.100000)"
                    fill="#000000" stroke="none">
                    <path d="M130 500 l0 -500 375 0 375 0 0 500 0 500 -375 0 -375 0 0 -500z
                    m213 322 c26 -28 31 -75 13 -109 -20 -39 -49 -47 -81 -21 -20 15 -25 28 -25
                    64 0 70 54 109 93 66z m355 -219 c45 -28 55 -74 60 -265 l4 -178 -56 0 -56 0
                    0 143 c0 94 -5 150 -13 167 -17 33 -57 38 -83 9 -17 -18 -19 -39 -22 -170 l-4
                    -149 -49 0 -49 0 0 225 0 225 50 0 c48 0 50 -1 50 -27 l0 -27 16 23 c34 48 98
                    58 152 24z m-338 -218 l0 -225 -55 0 -55 0 0 225 0 225 55 0 55 0 0 -225z"/>
                    </g>
                    </svg>
              </span>

              <span class="username">robert-chang</span>
            </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text">This is Robert Chang's personal website, powered by Jekyll, hosted on Github
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
