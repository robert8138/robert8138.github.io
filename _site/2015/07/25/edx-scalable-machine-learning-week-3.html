<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>EdX: Scalable Machine Learning Week 3 Notes</title>
  <meta name="description" content="Lecture Summary">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://yourdomain.com/2015/07/25/edx-scalable-machine-learning-week-3.html">
  <link rel="alternate" type="application/rss+xml" title="Robert Chang's Personal Website" href="http://yourdomain.com/feed.xml" />
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Robert Chang's Personal Website</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">EdX: Scalable Machine Learning Week 3 Notes</h1>
    <p class="post-meta">Jul 25, 2015</p>
  </header>

  <article class="post-content">
    <h3 id="lecture-summary">Lecture Summary</h3>

<ul>
  <li>
    <p>Big Picture: Supervised Learning Pipeline</p>

    <ul>
      <li>Obtain Raw Data</li>
      <li>Split Data into Training, Validation, and Test sets</li>
      <li>Feature Extraction</li>
      <li>Training</li>
      <li>Validation / Tuning Hyper-parameter</li>
      <li>only until we are satisfied, evaluate on test set</li>
      <li>Prediction</li>
    </ul>
  </li>
  <li>
    <p>Distributed ML: Computation &amp; Storage</p>

    <ul>
      <li>Computing closed form solution (i.e. normal equation)
        <ul>
          <li>Computation: O(nd^2 + d^3) operations</li>
          <li>Storage: O(nd + d^2) floats</li>
          <li>When n large, d small, the bottleneck is in storing X and computing X^TX.
            <ul>
              <li>Solution: distribute them to clusters</li>
              <li>Using outer product to compute X^TX</li>
            </ul>
          </li>
          <li>When n large, d large, we now have trouble storing and operating on X^TX
            <ul>
              <li>In big trouble -&gt; motivation for Gradient Descent</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Gradient Descent: I have enough intuition on the math
        <ul>
          <li>Parallel gradient descent
            <ul>
              <li>See slides to see why both storage and computation complexity got reduced</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>1st rule of thumb: Computation and storage should be linear in (n, d)</p>
      </li>
      <li>
        <p>2nd rule of thumb: Perform parallel and in memory computation</p>
      </li>
      <li>3rd rule of thumb: Minimize network communication
        <ul>
          <li>Stay local (model, data parallel)</li>
          <li>Reduce iteration (mini-batching)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="lab-3-summary">Lab 3 Summary</h3>

<p>In this lab, we get hands on with training a linear regression model in Spark. The task is to predict song release year based on 12 different audio features (I didn’t check what they are), and the main emphases are on:</p>

<ul>
  <li><strong>Part 1</strong>: Read and parse the initial dataset</li>
  <li><strong>Part 2</strong>: Create an Evaluate a baseline model</li>
  <li><strong>Part 3</strong>: Train (via gradient descent) and evaluate a linear regression model</li>
  <li><strong>Part 4</strong>: Train using MLlib and tune hyperparameters via grid search</li>
  <li><strong>Part 4</strong>: Add interactions between features</li>
</ul>

<p>The beauty of this exercise is that it:</p>

<ul>
  <li>It does a great job to <strong>modularize</strong> the code, so every task is easy to carry out.</li>
  <li>Links to <strong>documentations</strong> are immediately relevant, so I get unblocked quickly.</li>
</ul>

<p>This is the general analysis style that I should follow. Keep in mind that in real life, it’s very easy to 1). implement everything in one big function, and 2) you might need to google for a long time before figuring out the right syntax to unblock yourself.</p>

<p>Let’s talk about the code organization for each part</p>

<h4 id="part-1-read-and-parse-the-initial-dataset">Part 1: Read and parse the initial dataset</h4>
<p>Load in the text file as raw data</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">rawData</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="n">fileName</span><span class="p">,</span> <span class="n">numPartitions</span><span class="p">)</span></code></pre></div>

<p>create a method to parse the string into LabeledPoint, which is the data structure for differentiating label &amp; features</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">parsePoint</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts a comma separated unicode string into a `LabeledPoint`.</span>
<span class="sd">    &quot;&quot;&quot;</span></code></pre></div>

<p>Break data into training, validation, and test set</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">8</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">]</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">parsedTrainData</span><span class="p">,</span> <span class="n">parsedValData</span><span class="p">,</span> <span class="n">parsedTestData</span> <span class="o">=</span> <span class="n">parsedData</span><span class="o">.&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>
<span class="n">parsedTrainData</span><span class="o">.&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>
<span class="n">parsedValData</span><span class="o">.&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>
<span class="n">parsedTestData</span><span class="o">.&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span></code></pre></div>

<h4 id="part-2-create-and-evaluate-a-baseline-model">Part 2: Create and Evaluate a baseline model</h4>

<p>Before we make predictions using fancy models, it’s always a good idea to build a naive baseline model just so we can use it as the benchmark. Any additional efforts should improve our baseline performance.</p>

<p>The beauty here is how we break up the work, we create <strong>getLabeledPrediction</strong>, <strong>squaredError</strong>, <strong>calcRMSE</strong>:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">getLabeledPrediction</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">observation</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates predictions and returns a (label, prediction) tuple.</span>
<span class="sd">    &quot;&quot;&quot;</span></code></pre></div>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">squaredError</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">prediction</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates the the squared error for a single prediction.</span>
<span class="sd">    &quot;&quot;&quot;</span></code></pre></div>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">calcRMSE</span><span class="p">(</span><span class="n">labelsAndPreds</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates the root mean squared error for an `RDD` of (label, prediction) tuples.</span>
<span class="sd">    &quot;&quot;&quot;</span></code></pre></div>

<p>With these two functions, calculating the training, validation, and test error of the baseline model became easy</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">labelsAndPredsTrain</span> <span class="o">=</span> <span class="n">parsedTrainData</span><span class="o">.&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>
<span class="n">rmseTrainBase</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>

<span class="n">labelsAndPredsVal</span> <span class="o">=</span> <span class="n">parsedValData</span><span class="o">.&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>
<span class="n">rmseValBase</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>

<span class="n">labelsAndPredsTest</span> <span class="o">=</span> <span class="n">parsedTestData</span><span class="o">.&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>
<span class="n">rmseTestBase</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span></code></pre></div>

<h4 id="part-3-train-via-gradient-descent-and-evaluate-a-linear-regression-model">Part 3: Train (via gradient descent) and evaluate a linear regression model</h4>

<p>The third step is to code up gradient descent for linear regression. Again, codes are modularize here</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">gradientSummand</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">lp</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates the gradient summand for a given weight and `LabeledPoint`.</span>
<span class="sd">    &quot;&quot;&quot;</span></code></pre></div>

<p>Then we have the actual gradient descent algorithm</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">linregGradientDescent</span><span class="p">(</span><span class="n">trainData</span><span class="p">,</span> <span class="n">numIters</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates the weights and error for a linear regression model trained with gradient descent.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c"># The length of the training data</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">trainData</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
    <span class="c"># The number of features in the training data</span>
    <span class="n">d</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainData</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="c"># We will compute and store the training error after each iteration</span>
    <span class="n">errorTrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">numIters</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numIters</span><span class="p">):</span>
        <span class="c"># Use getLabeledPrediction from (3b) with trainData to obtain an RDD of (label, prediction)</span>
        <span class="c"># tuples.  Note that the weights all equal 0 for the first iteration, so the predictions will</span>
        <span class="c"># have large errors to start.</span>
        <span class="n">labelsAndPredsTrain</span> <span class="o">=</span> <span class="n">trainData</span><span class="o">.&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>
        <span class="n">errorTrain</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">calcRMSE</span><span class="p">(</span><span class="n">labelsAndPredsTrain</span><span class="p">)</span>

        <span class="c"># Calculate the `gradient`.  Make use of the `gradientSummand` function you wrote in (3a).</span>
        <span class="c"># Note that `gradient` sould be a `DenseVector` of length `d`.</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span> <span class="n">using</span> <span class="n">gradientSummand</span>

        <span class="c"># Update the weights</span>
        <span class="n">alpha_i</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">w</span> <span class="o">-=</span> <span class="o">&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>
    <span class="k">return</span> <span class="n">w</span><span class="p">,</span> <span class="n">errorTrain</span></code></pre></div>

<p>With this gradient descient algorithm implemented, we can now calculate the learned weights and training errors easily:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">numIters</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">weightsLR0</span><span class="p">,</span> <span class="n">errorTrainLR0</span> <span class="o">=</span> <span class="n">linregGradientDescent</span><span class="p">(</span><span class="o">&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span><span class="p">)</span>
<span class="n">labelsAndPreds</span> <span class="o">=</span> <span class="n">parsedValData</span><span class="o">.&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>
<span class="n">rmseValLR0</span> <span class="o">=</span> <span class="n">calcRMSE</span><span class="p">(</span><span class="n">labelsAndPreds</span><span class="p">)</span></code></pre></div>

<h4 id="part-4-train-using-mllib-and-perform-grid-search">Part 4: Train using MLlib and perform grid search</h4>
<p>The training part is mostly boiler plate, so there is nothing that is too surprising. Once we have the model, we can also do prediction easily, everything in one suite:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pyspark.mllib.regression</span> <span class="kn">import</span> <span class="n">LinearRegressionWithSGD</span>
<span class="c"># Values to use when training the linear regression model</span>
<span class="n">numIters</span> <span class="o">=</span> <span class="mi">500</span>  <span class="c"># iterations</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c"># step</span>
<span class="n">miniBatchFrac</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c"># miniBatchFraction</span>
<span class="n">reg</span> <span class="o">=</span> <span class="mf">1e-1</span>  <span class="c"># regParam</span>
<span class="n">regType</span> <span class="o">=</span> <span class="s">&#39;l2&#39;</span>  <span class="c"># regType</span>
<span class="n">useIntercept</span> <span class="o">=</span> <span class="bp">True</span>  <span class="c"># intercept</span>

<span class="c"># build model</span>
<span class="n">firstModel</span> <span class="o">=</span> <span class="n">LinearRegressionWithSGD</span><span class="o">.&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>

<span class="c"># weightsLR1 stores the model weights; interceptLR1 stores the model intercept</span>
<span class="n">weightsLR1</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>
<span class="n">interceptLR1</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>
<span class="k">print</span> <span class="n">weightsLR1</span><span class="p">,</span> <span class="n">interceptLR1</span>

<span class="n">samplePoint</span> <span class="o">=</span> <span class="n">parsedTrainData</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">samplePrediction</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>
<span class="k">print</span> <span class="n">samplePrediction</span></code></pre></div>

<p>The more interesting part is tuning hyper-parameter using grid-search, and it leverages all the modular function we wrote above:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">bestRMSE</span> <span class="o">=</span> <span class="n">rmseValLR1</span>
<span class="n">bestRegParam</span> <span class="o">=</span> <span class="n">reg</span>
<span class="n">bestModel</span> <span class="o">=</span> <span class="n">firstModel</span>

<span class="n">numIters</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">miniBatchFrac</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="k">for</span> <span class="n">reg</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegressionWithSGD</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">parsedTrainData</span><span class="p">,</span> <span class="n">numIters</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span>
                                          <span class="n">miniBatchFrac</span><span class="p">,</span> <span class="n">regParam</span><span class="o">=</span><span class="n">reg</span><span class="p">,</span>
                                          <span class="n">regType</span><span class="o">=</span><span class="s">&#39;l2&#39;</span><span class="p">,</span> <span class="n">intercept</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">labelsAndPreds</span> <span class="o">=</span> <span class="n">parsedValData</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">lp</span><span class="p">:</span> <span class="p">(</span><span class="n">lp</span><span class="o">.</span><span class="n">label</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">lp</span><span class="o">.</span><span class="n">features</span><span class="p">)))</span>
    <span class="n">rmseValGrid</span> <span class="o">=</span> <span class="n">calcRMSE</span><span class="p">(</span><span class="n">labelsAndPreds</span><span class="p">)</span>
    <span class="k">print</span> <span class="n">rmseValGrid</span>

    <span class="k">if</span> <span class="n">rmseValGrid</span> <span class="o">&lt;</span> <span class="n">bestRMSE</span><span class="p">:</span>
        <span class="n">bestRMSE</span> <span class="o">=</span> <span class="n">rmseValGrid</span>
        <span class="n">bestRegParam</span> <span class="o">=</span> <span class="n">reg</span>
        <span class="n">bestModel</span> <span class="o">=</span> <span class="n">model</span>
<span class="n">rmseValLRGrid</span> <span class="o">=</span> <span class="n">bestRMSE</span></code></pre></div>

<p>Another example of tuning hyper-parameter, alpha and numberIter at the same time</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">reg</span> <span class="o">=</span> <span class="n">bestRegParam</span>
<span class="n">modelRMSEs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">numIters</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegressionWithSGD</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">parsedTrainData</span><span class="p">,</span> <span class="n">numIters</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span>
                                              <span class="n">miniBatchFrac</span><span class="p">,</span> <span class="n">regParam</span><span class="o">=</span><span class="n">reg</span><span class="p">,</span>
                                              <span class="n">regType</span><span class="o">=</span><span class="s">&#39;l2&#39;</span><span class="p">,</span> <span class="n">intercept</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">labelsAndPreds</span> <span class="o">=</span> <span class="n">parsedValData</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">lp</span><span class="p">:</span> <span class="p">(</span><span class="n">lp</span><span class="o">.</span><span class="n">label</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">lp</span><span class="o">.</span><span class="n">features</span><span class="p">)))</span>
        <span class="n">rmseVal</span> <span class="o">=</span> <span class="n">calcRMSE</span><span class="p">(</span><span class="n">labelsAndPreds</span><span class="p">)</span>
        <span class="k">print</span> <span class="s">&#39;alpha = {0:.0e}, numIters = {1}, RMSE = {2:.3f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">numIters</span><span class="p">,</span> <span class="n">rmseVal</span><span class="p">)</span>
        <span class="n">modelRMSEs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rmseVal</span><span class="p">)</span></code></pre></div>

<h4 id="part-5-add-interactions-between-features">Part 5: Add interactions between features</h4>
<p>Finally, we build a more involved model with quadratic features, so most of the functions we defined above are still usable. First, define a function to create twoWayInteraction features:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">itertools</span>
<span class="k">def</span> <span class="nf">twoWayInteractions</span><span class="p">(</span><span class="n">lp</span><span class="p">):</span>
    <span class="s">&quot;&quot;&quot;Creates a new `LabeledPoint` that includes two-way interactions.</span></code></pre></div>

<p>Then we build a new dataset with the set of expanded features:</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># Transform the existing train, validation, and test sets to include two-way interactions.</span>
<span class="n">trainDataInteract</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>
<span class="n">valDataInteract</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span>
<span class="n">testDataInteract</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">FILL</span> <span class="n">IN</span><span class="o">&gt;</span></code></pre></div>

<p>Training and Testing are exactly the same as above, so I will not repeat myself.</p>

  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li>All Rights Reserved | 2015</li>
          <li><a href="mailto:robert8138@gmail.com">robert8138@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/robert8138">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">robert8138</span>
            </a>
          </li>
          

          
          <li>
            <a href="https://twitter.com/_rchang">
              <span class="icon  icon--twitter">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                  c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
                </svg>
              </span>

              <span class="username">_rchang</span>
            </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <ul class="social-media-list">
          
          <li>
            <a href="https://quora.com/Robert-Chang-1">
              <span class="icon  icon--twitter">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg"
                   width="100.000000pt" height="100.000000pt" viewBox="0 0 100.000000 100.000000"
                    preserveAspectRatio="xMidYMid meet">
                    <g transform="translate(0.000000,100.000000) scale(0.100000,-0.100000)"
                    fill="#000000" stroke="none">
                    <path d="M430 924 c-209 -45 -354 -270 -319 -494 23 -148 114 -275 239 -334
                    59 -28 74 -31 165 -31 91 0 105 3 160 30 285 144 325 556 73 756 -90 71 -206
                    98 -318 73z m160 -165 c95 -43 140 -117 140 -231 0 -63 -4 -80 -30 -125 -17
                    -29 -35 -53 -40 -53 -22 0 -9 -41 16 -52 23 -11 29 -10 44 10 34 42 58 21 36
                    -31 -31 -75 -112 -91 -169 -33 -30 30 -41 34 -99 38 -85 5 -150 43 -193 112
                    -37 60 -47 168 -22 229 56 132 195 192 317 136z"/>
                    <path d="M443 715 c-53 -23 -68 -64 -68 -185 0 -118 14 -159 65 -185 28 -15
                    90 -21 90 -9 0 22 -40 66 -72 79 -45 17 -47 27 -13 43 49 22 95 13 142 -30
                    l21 -20 8 47 c10 68 0 175 -20 213 -17 33 -66 62 -103 62 -10 -1 -32 -7 -50
                    -15z"/>
                    </g>
                    </svg>
              </span>

              <span class="username">Robert-Chang-1</span>
            </a>
          </li>
          

          
          <li>
            <a href="https://medium.com/@rchang">
              <span class="icon  icon--twitter">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg"
                   width="100.000000pt" height="100.000000pt" viewBox="0 0 100.000000 100.000000"
                    preserveAspectRatio="xMidYMid meet">
                    <g transform="translate(0.000000,100.000000) scale(0.100000,-0.100000)"
                    fill="#000000" stroke="none">
                    <path d="M200 705 c0 -24 5 -35 14 -35 8 0 18 -4 21 -10 8 -13 8 -307 0 -320
                    -3 -6 -13 -10 -21 -10 -9 0 -14 -11 -14 -35 l0 -35 90 0 90 0 0 34 c0 27 -4
                    35 -20 38 -19 3 -20 11 -23 145 -1 78 1 139 4 135 4 -4 26 -77 49 -162 22 -85
                    43 -163 46 -173 5 -14 14 -17 47 -15 l41 3 48 175 c26 96 50 180 52 185 3 6 5
                    -58 5 -142 1 -150 1 -152 -21 -155 -18 -2 -23 -10 -23 -33 l0 -30 108 -3 107
                    -3 0 36 c0 24 -5 35 -14 35 -8 0 -18 4 -21 10 -3 5 -6 77 -6 160 0 83 3 155 6
                    160 3 6 13 10 21 10 9 0 14 11 14 35 l0 36 -112 -3 -113 -3 -35 -127 c-19 -71
                    -37 -128 -40 -128 -3 0 -21 57 -40 128 l-35 127 -112 3 -113 3 0 -36z"/>
                    </g>
                    </svg>
              </span>

              <span class="username">rchang</span>
            </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col  footer-col-4">
        <ul class="social-media-list">
          
          <li>
            <a href="https://www.linkedin.com/pub/robert-chang/20/b17/877">
              <span class="icon  icon--twitter">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg"
                   width="100.000000pt" height="100.000000pt" viewBox="0 0 100.000000 100.000000"
                    preserveAspectRatio="xMidYMid meet">
                    <g transform="translate(0.000000,100.000000) scale(0.100000,-0.100000)"
                    fill="#000000" stroke="none">
                    <path d="M130 500 l0 -500 375 0 375 0 0 500 0 500 -375 0 -375 0 0 -500z
                    m213 322 c26 -28 31 -75 13 -109 -20 -39 -49 -47 -81 -21 -20 15 -25 28 -25
                    64 0 70 54 109 93 66z m355 -219 c45 -28 55 -74 60 -265 l4 -178 -56 0 -56 0
                    0 143 c0 94 -5 150 -13 167 -17 33 -57 38 -83 9 -17 -18 -19 -39 -22 -170 l-4
                    -149 -49 0 -49 0 0 225 0 225 50 0 c48 0 50 -1 50 -27 l0 -27 16 23 c34 48 98
                    58 152 24z m-338 -218 l0 -225 -55 0 -55 0 0 225 0 225 55 0 55 0 0 -225z"/>
                    </g>
                    </svg>
              </span>

              <span class="username">robert-chang</span>
            </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text">This is Robert Chang's personal website, powered by Jekyll, hosted on Github
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
